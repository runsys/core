// Code generated by "core generate"; DO NOT EDIT.

package parser

import (
	"cogentcore.org/core/tree"
	"cogentcore.org/core/types"
)

var _ = types.AddType(&types.Type{Name: "cogentcore.org/core/parse/parser.AST", IDName: "ast", Doc: "AST is a node in the abstract syntax tree generated by the parsing step\nthe name of the node (from tree.NodeBase) is the type of the element\n(e.g., expr, stmt, etc)\nThese nodes are generated by the parser.Rule's by matching tokens", Embeds: []types.Field{{Name: "NodeBase"}}, Fields: []types.Field{{Name: "TokReg", Doc: "region in source lexical tokens corresponding to this AST node -- Ch = index in lex lines"}, {Name: "SrcReg", Doc: "region in source file corresponding to this AST node"}, {Name: "Src", Doc: "source code corresponding to this AST node"}, {Name: "Syms", Doc: "stack of symbols created for this node"}}})

// NewAST returns a new [AST] with the given optional parent:
// AST is a node in the abstract syntax tree generated by the parsing step
// the name of the node (from tree.NodeBase) is the type of the element
// (e.g., expr, stmt, etc)
// These nodes are generated by the parser.Rule's by matching tokens
func NewAST(parent ...tree.Node) *AST { return tree.New[AST](parent...) }

var _ = types.AddType(&types.Type{Name: "cogentcore.org/core/parse/parser.Rule", IDName: "rule", Doc: "The first step is matching which searches in order for matches within the\nchildren of parent nodes, and for explicit rule nodes, it looks first\nthrough all the explicit tokens in the rule.  If there are no explicit tokens\nthen matching defers to ONLY the first node listed by default -- you can\nadd a @ prefix to indicate a rule that is also essential to match.\n\nAfter a rule matches, it then proceeds through the rules narrowing the scope\nand calling the sub-nodes..", Embeds: []types.Field{{Name: "NodeBase"}}, Fields: []types.Field{{Name: "Off", Doc: "disable this rule -- useful for testing and exploration"}, {Name: "Desc", Doc: "description / comments about this rule"}, {Name: "Rule", Doc: "the rule as a space-separated list of rule names and token(s) -- use single quotes around 'tokens' (using token.Tokens names or symbols). For keywords use 'key:keyword'.  All tokens are matched at the same nesting depth as the start of the scope of this rule, unless they have a +D relative depth value differential before the token.  Use @ prefix for a sub-rule to require that rule to match -- by default explicit tokens are used if available, and then only the first sub-rule failing that.  Use ! by itself to define start of an exclusionary rule -- doesn't match when those rule elements DO match.  Use : prefix for a special group node that matches a single token at start of scope, and then defers to the child rules to perform full match -- this is used for FirstTokenMap when there are multiple versions of a given keyword rule.  Use - prefix for tokens anchored by the end (next token) instead of the previous one -- typically just for token prior to 'EOS' but also a block of tokens that need to go backward in the middle of a sequence to avoid ambiguity can be marked with -"}, {Name: "StackMatch", Doc: "if present, this rule only fires if stack has this on it"}, {Name: "AST", Doc: "what action should be take for this node when it matches"}, {Name: "Acts", Doc: "actions to perform based on parsed AST tree data, when this rule is done executing"}, {Name: "OptTokenMap", Doc: "for group-level rules having lots of children and lots of recursiveness, and also of high-frequency, when we first encounter such a rule, make a map of all the tokens in the entire scope, and use that for a first-pass rejection on matching tokens"}, {Name: "FirstTokenMap", Doc: "for group-level rules with a number of rules that match based on first tokens / keywords, build map to directly go to that rule -- must also organize all of these rules sequentially from the start -- if no match, goes directly to first non-lookup case"}, {Name: "Rules", Doc: "rule elements compiled from Rule string"}, {Name: "Order", Doc: "strategic matching order for matching the rules"}, {Name: "FiTokenMap", Doc: "map from first tokens / keywords to rules for FirstTokenMap case"}, {Name: "FiTokenElseIndex", Doc: "for FirstTokenMap, the start of the else cases not covered by the map"}, {Name: "ExclKeyIndex", Doc: "exclusionary key index -- this is the token in Rules that we need to exclude matches for using ExclFwd and ExclRev rules"}, {Name: "ExclFwd", Doc: "exclusionary forward-search rule elements compiled from Rule string"}, {Name: "ExclRev", Doc: "exclusionary reverse-search rule elements compiled from Rule string"}, {Name: "setsScope", Doc: "setsScope means that this rule sets its own scope, because it ends with EOS"}, {Name: "reverse", Doc: "reverse means that this rule runs in reverse (starts with - sign) -- for arithmetic\nbinary expressions only: this is needed to produce proper associativity result for\nmathematical expressions in the recursive descent parser.\nOnly for rules of form: Expr '+' Expr -- two sub-rules with a token operator\nin the middle."}, {Name: "noTokens", Doc: "noTokens means that this rule doesn't have any explicit tokens -- only refers to\nother rules"}, {Name: "onlyTokens", Doc: "onlyTokens means that this rule only has explicit tokens for matching -- can be\noptimized"}, {Name: "tokenMatchGroup", Doc: "tokenMatchGroup is a group node that also has a single token match, so it can\nbe used in a FirstTokenMap to optimize lookup of rules"}}})

// NewRule returns a new [Rule] with the given optional parent:
// The first step is matching which searches in order for matches within the
// children of parent nodes, and for explicit rule nodes, it looks first
// through all the explicit tokens in the rule.  If there are no explicit tokens
// then matching defers to ONLY the first node listed by default -- you can
// add a @ prefix to indicate a rule that is also essential to match.
//
// After a rule matches, it then proceeds through the rules narrowing the scope
// and calling the sub-nodes..
func NewRule(parent ...tree.Node) *Rule { return tree.New[Rule](parent...) }

// SetOff sets the [Rule.Off]:
// disable this rule -- useful for testing and exploration
func (t *Rule) SetOff(v bool) *Rule { t.Off = v; return t }

// SetDesc sets the [Rule.Desc]:
// description / comments about this rule
func (t *Rule) SetDesc(v string) *Rule { t.Desc = v; return t }

// SetRule sets the [Rule.Rule]:
// the rule as a space-separated list of rule names and token(s) -- use single quotes around 'tokens' (using token.Tokens names or symbols). For keywords use 'key:keyword'.  All tokens are matched at the same nesting depth as the start of the scope of this rule, unless they have a +D relative depth value differential before the token.  Use @ prefix for a sub-rule to require that rule to match -- by default explicit tokens are used if available, and then only the first sub-rule failing that.  Use ! by itself to define start of an exclusionary rule -- doesn't match when those rule elements DO match.  Use : prefix for a special group node that matches a single token at start of scope, and then defers to the child rules to perform full match -- this is used for FirstTokenMap when there are multiple versions of a given keyword rule.  Use - prefix for tokens anchored by the end (next token) instead of the previous one -- typically just for token prior to 'EOS' but also a block of tokens that need to go backward in the middle of a sequence to avoid ambiguity can be marked with -
func (t *Rule) SetRule(v string) *Rule { t.Rule = v; return t }

// SetStackMatch sets the [Rule.StackMatch]:
// if present, this rule only fires if stack has this on it
func (t *Rule) SetStackMatch(v string) *Rule { t.StackMatch = v; return t }

// SetAST sets the [Rule.AST]:
// what action should be take for this node when it matches
func (t *Rule) SetAST(v ASTActs) *Rule { t.AST = v; return t }

// SetActs sets the [Rule.Acts]:
// actions to perform based on parsed AST tree data, when this rule is done executing
func (t *Rule) SetActs(v Acts) *Rule { t.Acts = v; return t }

// SetOptTokenMap sets the [Rule.OptTokenMap]:
// for group-level rules having lots of children and lots of recursiveness, and also of high-frequency, when we first encounter such a rule, make a map of all the tokens in the entire scope, and use that for a first-pass rejection on matching tokens
func (t *Rule) SetOptTokenMap(v bool) *Rule { t.OptTokenMap = v; return t }

// SetFirstTokenMap sets the [Rule.FirstTokenMap]:
// for group-level rules with a number of rules that match based on first tokens / keywords, build map to directly go to that rule -- must also organize all of these rules sequentially from the start -- if no match, goes directly to first non-lookup case
func (t *Rule) SetFirstTokenMap(v bool) *Rule { t.FirstTokenMap = v; return t }

// SetRules sets the [Rule.Rules]:
// rule elements compiled from Rule string
func (t *Rule) SetRules(v RuleList) *Rule { t.Rules = v; return t }

// SetOrder sets the [Rule.Order]:
// strategic matching order for matching the rules
func (t *Rule) SetOrder(v ...int) *Rule { t.Order = v; return t }
